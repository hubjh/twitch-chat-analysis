# Twitch 실시간 데이터 파이프라인

</br>
</br>

# ☑︎ 프로젝트 결과



## 데이터 시각화

[http://15.164.106.168:8080/twitch-plotly.html](http://15.164.106.168:8080/twitch-plotly.html)


**Twitch**의 **API, Chatbot** 기능을 활용하여 실시간 데이터 파이프라인을 구축하여 **방송 정보, 채팅 로그** 데이터 시각화를 했다.

**2023-04-08**부터 수집을 시작했고 **2023-05-23 20:34** 기준 **18,253,266**개의 채팅 데이터를 수집했다.

## **결과의 의미**

|  | 개인 | 팀 |
| --- | --- | --- |
| 얻은 것 | 이전의 파이프라인보다 많은 천만 단위의 데이터를 수집했다 | 데이터 플랫폼 서버의 테스트를 위한 데이터 파이프라인을 추가 |

# ✎ 프로젝트 배경


| 프로젝트 인원 | 2명 |
| :--- | :--- |
| 프로젝트의 목표 | 실시간 방송 중인 twitch 방송 데이터 시각화를 위한 데이터 파이프라인 구축</br></br>1. 편의성, 안정성을 위해 외부에 제공해주는 API를 활용하여 데이터 수집 (API limit가 높을수록 좋다.)</br>2. 이해가 쉽게 본인이 관심 있는 분야의 데이터면 좋다.</br>3. 전보다 더 많은 데이터를 수집하는 데이터 파이프라인이어야 한다.</br></br>수집하고자 하는 데이터</br></br>1. 현재 생방송 중인 방송들의 정보 (방송 시작 시간, 방송 중인 게임 이름, 시청자 수, 방송 제목, 방송 채널 이름 등등)</br>2. 현재 생방송 중인 방송 시청자들의 실시간 채팅 로그</br></br>데이터 시각화를 하는 이유</br></br>1. 데이터 필터링이 올바르게 되었는지 테스트</br>2. 많은 양의 데이터를 한눈에 보기 위함 |
| 팀의 목표 | 데이터플랫폼 서버의 인프라 성능, 안정성 테스트</br></br>1. k8s에 pod로 올려놓은 Spark, Airflow 등이 안정적으로 작동하는지 테스트</br>2. k8s 노드들의 리소스(CPU, Memory) 이상 테스트</br>3. 이상 발견 시 문제점을 해결한다. |
| 팀 내 나의 역할  | 1. 실시간 데이터 파이프라인 구축</br>2. 수집한 데이터 시각화</br>3. Amazon lightsail서버에서 Docker에서 Nginx 컨테이너를 통한 서비스 |
| 팀의 문제 혹은 기회 상황 | 프로젝트</br>1. 사용해본 적 없는 Kafka를 사용해야 한다. 하지만 팀장이 사용법을 알려줄 수 있다.</br>2. 릴리즈 노트(80포트)를 서비스할 때 사용한 Amazon lightsail 서버에(8080포트)가 비어있다. |
| 개발 기간 | 2023.03 ~ 2023.04 |
| 개발 언어  | Python |
| 개발 환경 | 온프레미스 환경 Ubuntu:20.04 |
| 사용 기술 | Main : 주로 사용한 기술</br></br>• Hadoop</br>    - 수집한 채팅 로그, streams 데이터 소스와 Spark로 가공한 데이터 저장</br></br>• Docker</br>    - 개발 단계에서 테스트용 컨테이너 생성</br></br>• Kubernetes</br>    - 채팅 로그, streams 데이터를 수집하는 파드를 디플로이먼트로 관리하기 위해 사용</br></br>• Spark</br>    - 수집한 데이터를 필터링할 때 사용</br></br>• Airflow</br>    - Spark 실행 스케쥴 관리</br>—————————————————————————————————————————</br>Sub : 사용만 해본 기술</br></br>• Kafka</br>    - 멀티 프로세스로 방송 별로 수집되는 채팅 데이터를 저장</br></br>• Amazon lightsail </br>    - Amazon lightsail를 직접 구성한 것은 아니고 ssh접속하여 Docker를 사용 |

# 🧩 프로젝트 과정



### 조사내용

# ****Twitch API****



### ※ Twitch에서 대부분의 Twitch 리소스에 액세스하려면 **OAuth 액세스 토큰이 필요**하다.

## 사용하고자 하는 Twitch API


🔖 ***GET /streams***



| API | GET https://api.twitch.tv/helix/streams |
| --- | --- |
| 기능 | 모든 방송의 목록을 가져온다. 요청 파라미터를 통해서 응답 값을 필터링이 가능하다. |
| 필요한 것 | 해당 api를 사용하려면 user access token 또는 app access token이 필요하다. |

현재 생방송 중인 방송들의 정보를 얻기 위해 사용했다.

### **Request Query Parameters**

| Parameter | Description |
| :--- | :--- |
| user_id | 스트림 목록을 필터링하는 데 사용되는 유저 ID입니다. </br>방송 중인 사용자의 스트림만 반환합니다. </br>최대 100개의 ID를 지정할 수 있습니다. |
| user_login | 스트림 목록을 필터링하는 데 사용되는 유저 로그인 이름입니다. </br>방송 중인 사용자의 스트림만 반환합니다. </br>최대 100개의 로그인 이름을 지정할 수 있습니다. |
| game_id | 스트림 목록을 필터링하는 데 사용되는 게임(카테고리) ID입니다. </br>게임(카테고리)을 브로드캐스팅하는 스트림만 반환합니다. </br>최대 100개의 ID를 지정할 수 있습니다. |
| type | 스트림 목록을 필터링할 스트림 유형입니다.</br>- all : 모두</br>- live : 생방송만 |
| language | 스트림 목록을 필터링하는 데 사용되는 언어 코드입니다. </br>지정된 언어로 브로드캐스트하는 스트림만 반환합니다. |
| first | 응답에서 페이지당 반환할 최대 항목 수입니다. 최소 페이지 크기는 페이지당 1개 항목이고 최대값은 페이지당 100개 항목입니다. 기본값은 20입니다. |
| before | 결과의 이전 페이지를 가져오는 데 사용되는 커서 |
| after | 결과의 다음 페이지를 가져오는 데 사용되는 커서 |

### **Response Body**

| Field | Description |
| :--- | :--- |
| id | 스트림을 식별하는 ID입니다. 나중에 이 ID를 사용하여 주문형 비디오(VOD)를 조회할 수 있습니다. |
| user_id | 스트림을 브로드캐스팅하는 유저의 ID입니다. |
| user_login | 유저의 로그인 이름입니다. |
| user_name | 유저의 표시된 이름입니다. |
| game_id | 플레이 중인 카테고리 또는 게임의 ID입니다. |
| game_name | 플레이 중인 카테고리 또는 게임의 이름입니다. |
| type | 스트림의 유형입니다. 가능한 값은 다음과 같습니다.</br>- live : 생방송 |
| title | 스트림의 제목입니다. 설정되지 않은 경우 빈 문자열입니다. |
| tags | 스트림에 적용된 태그입니다. |
| viewer_count | 스트림을 시청하는 유저 수입니다. |
| started_at | 브로드캐스트가 시작된 UTC 날짜 및 시간(RFC3339 형식)입니다. |
| language | 스트림이 사용하는 언어입니다. |
| thumbnail_url | 스트림의 마지막 5분 동안의 프레임 이미지에 대한 URL입니다. URL( )의 너비 및 높이 자리 표시자를 {width}x{height}원하는 이미지 크기(픽셀)로 바꿉니다. |
| tag_ids | 2023년 2월 28일부터 이 필드는 지원 중단되었으며 빈 배열만 반환합니다. |
| is_mature | 스트림이 성인용인지 아닌지를 나타내는 bool 값입니다. |
| pagination | 결과 목록을 통해 페이징하는 데 사용되는 정보입니다. |
| cursor | 결과의 다음 페이지를 가져오는 데 사용되는 커서 |

### 속도 제한

<aside>
🔖 분당 800회

</aside>

| Authentication | Refill Rate | Bucket Size |
| --- | --- | --- |
| Bearer token is provided | 800 points per minute, per user | 800 points |

# ****Twitch Chat & Chatbots****

---

### ※ **Twitch는 챗봇**이 WebSocket 또는 TCP 연결을 사용하여 **Twitch 채팅방에 연결할 수 있는 인터넷 릴레이 채팅(IRC) 인터페이스를 제공**된다. 연결되면 **봇은 채팅 메시지를 보내고 받을 수 있다.**

### 사용하고자 하는 Twitch Interface

<aside>
🔖 **Chatbots**

</aside>

| 기능 | user access token, 원하는 스트리머의 채널 이름을 Twitch irc서버에 제공하면 해당 채널 채팅방에 챗봇을 참여시켜서 채팅 메시지를 주고받을 수 있다. |
| :--- | :--- |
| 필요한 것 | 해당 기능을 사용하려면 user access token이 필요하다. |

### ⚔️ TCP vs WebSocket


🔖 ***TCP 방식 채택***


|  | TCP | WebSocket |
| --- | --- | --- |
| 사용 유무 |  O | X |
| 이유 | Python의 표준 라이브러리인 socket 모듈을 사용하여 간편하게 구현 가능| Python의 표준 라이브러리인 socket 모듈로는 WebSocket을 직접 처리할 수 없다. 별도의 라이브러리나 프레임워크를 사용해야 한다. |

Python의 socket 모듈을 사용하여 간편하게 구현 가능하기 때문에 선택했다.

### 속도 제한

<aside>
🔖 30초당 메시지 20개

</aside>

| 한계 | 설명 |
| --- | --- |
| 30초당 메시지 20개 | 사용자가 채널의 브로드캐스터 또는 중재자가 아닌 경우 봇은 30초당 최대 20개의 메시지를 보낼 수 있습니다. |
| 30초당 메시지 100개 | 사용자가 채널의 브로드캐스터 또는 중재자인 경우 봇은 30초당 최대 100개의 메시지를 보낼 수 있습니다. |
| 30초당 7,500개의 메시지 | 봇은 모든 채널에서 30초당 7,500개의 메시지를 보내는 것으로 제한됩니다. 이는 봇이 30초당 10개의 메시지를 750개의 서로 다른 채널로 보낼 수 있음을 의미합니다. 그러나 예를 들어 30초당 20개 메시지 제한을 초과하기 때문에 단일 채널에 30초당 7,500개 메시지를 보낼 수 없습니다. |

### Python으로 유저와 챗봇과의 소켓 통신 흐름

1. 유저가 Python에서 socket 통신으로 Twitch irc 서버에 PASS, NICK (**user access token**, IRC에서 사용할 자신의 닉네임)을 보낸다.
2. irc 서버가 봇을 성공적으로 인증하면 JOIN 메시지로 원하는 채널 채팅방의 로그인 이름(스트리머 채널 이름)을 보낸다.
3. 봇이 채팅방에 성공적으로 참여하면 twitch의 환영 메시지를 유저에게 보낸다. (PING)
4. 유저가 Python의 반복문을 통해 irc 서버에게 PING 메시지를 if문으로 받게 되면 PONG 메시지를 보내서 지속적으로 PING 메시지를 받는다. 이때 PING을 통해 들어오는 채팅방의 채팅 로그를 버퍼로 받아서 활용한다.
5. 방송 중인 스트리머가 방송을 종료하는 경우 
**유저와 채팅방의 봇이 소켓 통신 종료가 안 되기 때문에 따로 통신을 종료해야 한다.**

## 챗봇이 가져오는 메시지 구문

# Ex)

`:lovingt3s!lovingt3s@lovingt3s.tmi.twitch.tv PRIVMSG #lovingt3s :!dilly`

`nick` : `lovingt3s` 유저의 닉네임
`host` : `lovingt3s@lovingt3s.tmi.twitch.tv` 유저의 호스트 정보
`command` : `PRIVMSG` 유저가 실행한 명령어
`channel` : `#lovingt3s` 채팅이 전송된 채널, twitch 채팅에서 사용되는 채널 이름
`parameters` : `!dilly` 명령어에 대한 추가적인 매개변수 또는 정보, 유저가 보낸 채팅 문자

## 챗봇이 가져오는 메시지로그

### **※ Twitch IRC 서버가 메시지를 보낼 때 단일 메시지 또는 여러 메시지를 포함할 수 있다.**

# Ex)

**2023-04-31 T14:00:00** 챗봇이 가져온 메시지
`:lovingt3s!lovingt3s@lovingt3s.tmi.twitch.tv PRIVMSG #lovingt3s :!dilly/r/n`

**2023-04-31 T14:00:01** 챗봇이 가져온 메시지

`:catfish99!catfish99@catfish99.tmi.twitch.tv PRIVMSG #lovingt3s :Meow/r/n`
`:abcdef!abcdef@abcdef.tmi.twitch.tv PRIVMSG #abcdef :ㅋㅋㅋㅋ/r/n`
`:sandwich33@sandwich33.tmi.twitch.tv PRIVMSG #lovingt3s :happy/r/n`

수집되는 채팅의 시간대가 겹치는 경우 개행문자`/r/n`를 통해 메시지를 구분한 문자열을 받게 된다.

# ****OAuth Access Tokens****

---

### ※ **토큰은 영원하지 않다.**

다음과 같은 이유로 액세스 및 갱신 토큰이 무효화 될 수 있다.

- 토큰이 만료
- 사용자가 비밀번호를 변경
- Twitch가 토큰을 취소
- 사용자가 계정의 ****앱 연결을 해제

토큰이 유효하지 않게 되면 API 요청에서 HTTP 상태 코드 401 Unauthorized를 반환합니다. 이 경우 새 액세스 토큰을 가져와야 한다.

### ⚔️ 사용자 엑세스 토큰 vs 앱 엑세스 토큰

트위치 서버에서 부여받을 수 있는 토큰은 두 종류가 있다.

<aside>
🔖 user access token 채택

</aside>

|  | user access token | app access token |
| --- | --- | --- |
| 특징 | 유저의 민감한 데이터에 액세스할 수 있다. | 유저의 민감하지 않은 데이터에만 액세스할 수 있다. |

프로젝트에서 핵심적으로 사용될 Twitch Chatbot를 사용하기 위해 user access token이 필요했다.

### ⚔️ user access token 토큰 부여 방법

<aside>
🔖 Authorization code grant flow 채택

</aside>

|  | Authorization code grant flow | Implicit grant flow |
| --- | --- | --- |
| 설명 | 앱이 서버를 사용하고, 클라이언트 암호를 안전하게 저장할 수 있고, Twitch API에 서버 간 요청을 할 수 있는 경우 이 흐름을 사용하세요. | 앱이 서버를 사용하지 않는 경우 이 흐름을 사용합니다. 예를 들어 앱이 클라이언트 측 JavaScript 앱 또는 모바일 앱인 경우 이 흐름을 사용합니다. |
| 토큰 유효 기간 | 4시간 | 60일 |
| refresh token</br>(토큰 새로고침 유무) | O | X |

트위치 서버와 요청이 가능한 환경이고, 한 번 토큰을 받아 두면 refresh token으로 트위치 서버에서 새로운 토큰을 받을 수 있기 때문에 선택했다.

### 토큰 유효 기간

<aside>
🔖 4시간

</aside>

# 시각화

---

### ⚔️ Tableau vs Plotly

<aside>
🔖 **Plotly 사용**

</aside>

|  | Tableau | Plotly |
| --- | --- | --- |
| 비용 | 발생 | 없음 |

Python으로 데이터 시각화를 비용 없이 간단하게 할 수 있어 선택했다.

# Kafka

### ⚔️ Kafka를 사용해서 채팅 로그를 적재하는 이유

### 배경

---

1. 챗봇이 가져오는 메시지를 저장하는 방법이 필요하다.
2. 프로젝트를 처음 진행할 당시에 데이터 플랫폼 서버에 Kafka는 설치가 안 되어 있었다.
3. 데이터 손실이 없는 안정성이 높은 방법이 필요하다.

<aside>
🔖 **Kafka를 사용**

</aside>

|  | Kafka를 사용 | API server를 사용 | 컨테이너 내의 로컬에 저장 |
| --- | --- | --- | --- |
| 설명 | 데이터 플랫폼 서버 내에 Kafka를 설치 후 챗봇의 수집 데이터를 Kafka에 적재 후 HDFS에 따로 적재한다. | 챗봇의 메시지를 API로 보내서 쌓아두는 서버를 따로 만든다. | 챗봇의 메시지를 프로그램이 동작하는 컨테이너 내의 로컬에 저장한다.</br>이 로컬은 NFS와 마운트 되어있다. |
| 장점 | + 나중에 서버 내에 확장성을 위해 Kafka를 추가할 계획이 있었다.</br>+ 직접 만드는 것보다 안정성이 더 높다.</br>+ 서버가 다운되더라도 커밋에 의해 마지막으로 처리한 메시지의 위치부터 HDFS로 데이터를 적재할 수 있다. | + 만드는 게 간단하다.</br>+ 컨테이너 내의 로컬에 저장하는것 보다 속도가 빠르다 | + 만드는 게 간단하다. |
| 단점 | - 데이터 플랫폼 서버에 Kafka를 설치하는 작업을 해야 한다.</br>- Kafka에 관해 추가적인 공부를 해야 한다. | - API server가 다운되면 챗봇 메시지 수집에 문제가 생긴다.</br>- 직접 프로그램을 짜는 것이니 Kafka보다 안정성이 떨어진다. | - 수집과 저장의 기능이 하나의 프로그램에 모여있어서 한쪽의 문제가 생기면 프로그램 전체를 다시 실행해야 하는데 이 경우 데이터 소실이 우려된다.</br>- 컨테이너의 로컬을 NFS와 마운트 해야 하는데 네트워크 지연으로 속도가 느리다.</br>- 직접 프로그램을 짜는 것이니 Kafka보다 안정성이 떨어진다. |

데이터 손실이 최대한 적은 안정성이 높고 나중에 확장할 기능이었기에 Kafka를 사용하는 것으로 정했다.

# 프로그램 기능

---

| 기능 목록 | 배경 | 목적 | 조건 |
| --- | --- | --- | --- |
| 트위치 토큰 매니저 | twitch api, twitch chatbot 기능을 사용하려면 user access token이 필요하다.</br>twitch 서버에 토큰을 요청하면 토큰, 토큰의 기한정보, refresh 토큰을 얻을 수 있다.  | 토큰의 사용횟수 초과, 만료로  사용을 못 하게 되면 refresh 토큰으로 토큰을 재발급</br>발급 받은 토큰 정보들을 파라미터 스토어에 갱신한다. | 1. while 문으로 계속 동작해야 한다.</br>2. 30분마다 refresh token으로 access token을 재발급한다.</br>3. twitch에서 받은 토큰 정보는 파라미터 스토어 저장 경로에 갱신한다.</br>4. k8s의 디플로이먼트로 관리한다. |
| 파라미터 스토어 | while문으로 계속 동작하는 프로그램들 내부에서 트위치의 토큰, 현재 스트림 정보 등을 갱신하는 기능이 필요했다. | Python requests모듈의 api 요청으로 데이터를 다른 곳에 저장하고 사용할 수 있는 기능 | 데이터 플랫폼 서버 내에서 Docker 이미지로 k8s의 디플로이먼트에서 FastAPI로  restful api 서버를 만든다. </br>파라미터 스토어 서버의 기능은</br>1. 데이터 플랫폼 서버의 NFS에 json 파일을 생성한다.</br>2. Python requests 모듈의 put의 매개변수로 (데이터를 저장할 json파일의 경로, 저장할 데이터)</br>를 파라미터 스토어 서버에게 요청하면 데이터를 json 파일에 덮어쓰기로 저장할 수 있다. </br>3. Python requests 모듈의 get의 매개변수로 (데이터를 저장한 json파일의 경로)를 파라미터 스토어 서버에게 요청하면 데이터를 json 파일에서 불러올 수 있다. </br>4. Python requests 모듈의 delete의 매개변수로 (데이터를 저장한 json파일의 경로)를 파라미터 스토어 서버에게 요청하면 json 파일이 해당 경로에 있으면 삭제한다. |
| 스트림 수집기 | 실시간 방송 중인 채널의 정보를 얻기 위해 GET /streams 응답 데이터 중 생방송 상태인 데이터만 파라미터 스토어에 갱신하는데 필요했다.| 파라미터 스토어에 갱신되는 토큰으로 GET /streams 요청을 n 분마다 twitch API 서버에 보낸다.</br>현재 생방송 중인 스트리머 정보들을 파라미터 스토어에 갱신한다.</br>오늘 GET /streams 요청하여 받은 데이터들을 누적해서 스트림 수집기의 변수에 넣어두고 HDFS의 red 테이블에 append로 적재한다.| 1. while 문으로 계속 동작해야 한다.</br>2. while 문이 동작할 때마다 파라미터 스토어를 통해 설정값(while 문 인터벌, 수집하고자 하는 스트리머 채널명 리스트, token정보)를 get 할 수 있어야한다.</br>3. 라이브 방송만 필터해서 적재한다.</br>4. 스트림 수집기 변수에 { 오늘의 누적 데이터, 현재 데이터, api 요청날짜 }형태로 적재한다.</br>5. while 문이 동작할 때마다 api 요청을 보낸다.</br>6. while 문이 동작할 때마다 HDFS red 테이블에 오늘의 누적 데이터를 덮어쓰기로 적재한다.</br>7. 현재 스트리밍 정보를 파라미터 스토어에 갱신 해야 한다.</br>8. 날짜가 바뀌면 변수에서 오늘의 누적 데이터를 비워야 한다.</br>9. k8s의 디플로이먼트로 관리한다. |
| 챗봇 생성기 | 파라미터 스토어에 갱신되는 현재 생방송 중인 스트리머 채팅 채널 각각에 챗봇을 생성하는데 필요했다.</br>소켓 통신 중에 방송이 종료된 채팅방의 챗봇은 자동으로 통신 종료가 안 되기 때문에 관리 기능이 필요했다.  | 파라미터 스토어에서 생방송 정보를 읽어서 트위치 챗봇을 생성하고 관리</br>트위치 챗봇을 생성하는 프로세스에는 Producer를 통해 챗봇이 가져오는 방송 채팅 로그를 Kafka에 적재한다. | 1. while 문으로 계속 동작해야 한다.</br>2. while 문이 동작할 때마다 파라미터 스토어를 통해 설정값(token정보, 현재 스트리밍 정보)을 get할 수 있어야한다.</br>3. 현재 스트리밍 정보에서 복수의 스트리머의 정보가 있으므로 파이썬의 멀티프로세싱 라이브러리를 사용해서 while문으로 chatbot과 소켓프로그래밍 하는 객체를 생성한다.</br>4. chatbot 소켓프로그래밍 객체는 Kafka producer를 통해 Kafka에 채팅 로그를 적재한다.</br>5. chatbot 소켓프로그래밍 객체 생성 시 프로세스의 정보를 프로그램 내의 변수에 넣어서 관리한다.</br>6. while 문이 동작 할 때 마다 현재 스트리밍 정보와 chatbot 프로세스 변수를 비교해서 방송이 종료된 chatbot 객체를 종료시킨다.</br>7. k8s의 디플로이먼트로 관리한다. |
| 카프카 채팅 데이터 하둡 적재기 | 챗봇들에 의해 Kafka에 적재된 채팅 로그들을 하둡에 적재하는데 필요했다. | Kafka에 적재된 채팅 로그들을 일정 시간마다 Consumer를 사용하여 HDFS red 테이블에 append 방식으로 적재한다. | 1. while 문으로 계속 동작해야 한다.</br>2. HDFS에 red 테이블에 append방식으로 적재해야 한다.</br>3. while 문이 동작할 때마다 kafka consumer로 채팅 로그를 가져와서 HDFS에 적재한다.</br>4. k8s의 디플로이먼트로 관리한다. |
| yellow 가공 스크립트 | red 테이블에서 필요한 데이터 추출과 중복데이터를 제거하는데 필요했다. | red 테이블에 적재된 채팅 로그, 스트림목록 데이터를 가공하여 yellow 테이블에 적재한다. | 1. Airflow로 1시간마다 실행한다.</br>2. 중복 데이터 제거를 해야 한다. |
| 데이터 시각화 | Python으로 비용없이 간단하게 시각화를 하고 싶었다. | 주피터 노트북에서 spark로 sql문을 요청해서 집계한 데이터를 python의 plotly 라이브러리로 시각화한다. | 1. Python의 Plotly 라이브러리를 사용한다.</br>2. 시각화 자료를 만들기 좋게 Jupyter에서 만든다.</br>3. 완성한 자료는 Html로 저장한다.</br>4. HTML파일을 Amazon lightsail 서버에 넣고 Docker의 Nginx 컨테이너를 만들어서 8080포트로 서비스한다. |
